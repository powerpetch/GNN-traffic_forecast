# üìä ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• - Data Processing (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)

## üìö ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç

1. [‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ](#‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ)
2. [‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•](#‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
3. [Feature Engineering](#feature-engineering)
4. [‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á](#‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á)
5. [‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•](#‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
6. [Data Augmentation](#data-augmentation)

---

## üì• ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ

### **1. PROBE Data (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• GPS)**

**‡∏ó‡∏µ‡πà‡∏°‡∏≤:** ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `Data/PROBE-202401/`, `PROBE-202402/`, etc.

**‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå:**
```
PROBE-202401/
‚îú‚îÄ‚îÄ 20240101.csv.out
‚îú‚îÄ‚îÄ 20240102.csv.out
‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ 20240131.csv.out
```

**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå:**
```csv
timestamp,location_id,latitude,longitude,speed,heading,quality
2024-01-01 00:05:00,LOC001,13.7563,100.5018,45.5,90.0,0.85
2024-01-01 00:10:00,LOC001,13.7563,100.5018,42.0,90.0,0.90
2024-01-01 00:15:00,LOC002,13.7600,100.5050,38.5,180.0,0.75
...
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå:**

| Column | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ | ‡∏´‡∏ô‡πà‡∏ß‡∏¢ | ‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡πà‡∏≤ |
|--------|----------|------|---------|
| **timestamp** | ‡∏ß‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å | datetime | 2024-01-01 00:00:00 |
| **location_id** | ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà | string | LOC001-LOC217 |
| **latitude** | ‡∏û‡∏¥‡∏Å‡∏±‡∏î latitude | degrees | 13.5-14.0 (‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø) |
| **longitude** | ‡∏û‡∏¥‡∏Å‡∏±‡∏î longitude | degrees | 100.3-100.8 (‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø) |
| **speed** | ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ | km/h | 0-120 |
| **heading** | ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà | degrees | 0-360 |
| **quality** | ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• | score | 0.0-1.0 |

### **2. OpenStreetMap Data (‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ñ‡∏ô‡∏ô)**

**‡∏ó‡∏µ‡πà‡∏°‡∏≤:** ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `Data/hotosm_tha_roads_lines_gpkg/`

**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ:**
- ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ñ‡∏ô‡∏ô (geometry)
- ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏ô‡∏ô
- ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ñ‡∏ô‡∏ô (highway type)
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ñ‡∏ô‡∏ô

### **3. Traffic Events (‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£)**

**‡∏ó‡∏µ‡πà‡∏°‡∏≤:** ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `iTIC-Longdo-Traffic-events-2022/`

**‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå:**
- ‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏ï‡∏∏ (accidents)
- ‡∏Å‡∏≤‡∏£‡∏Å‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á (construction)
- ‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏û‡∏¥‡πÄ‡∏®‡∏© (special events)
- ‡∏Å‡∏≤‡∏£‡∏õ‡∏¥‡∏î‡∏ñ‡∏ô‡∏ô (road closures)

---

## üßπ ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

### **1. ‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥ (Outlier Removal)**

**‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• GPS ‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£:**

#### **A. ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥**
```python
# ‡∏•‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
df = df[df['speed'] >= 0]         # ‡πÑ‡∏°‡πà‡∏ï‡∏¥‡∏î‡∏•‡∏ö
df = df[df['speed'] <= 150]       # ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 150 km/h (‡πÉ‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á)

# ‡∏•‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
# ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏ñ‡∏¢‡∏∑‡∏ô ‡πÅ‡∏ï‡πà speed = 100 km/h
df = df[~((df['speed'] > 80) & (df['location_type'] == 'intersection'))]
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏ï‡∏¥‡∏î‡∏•‡∏ö:** ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‚Üí ‡∏•‡∏ö‡∏ó‡∏¥‡πâ‡∏á
- **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏™‡∏π‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ:** ‡πÉ‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á > 150 km/h ‚Üí ‡∏ô‡πà‡∏≤‡∏à‡∏∞‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
- **‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏ö‡∏ó:** ‡∏à‡∏∏‡∏î‡∏ï‡∏±‡∏î‡∏ñ‡∏ô‡∏ô‡πÅ‡∏ï‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏™‡∏π‡∏á ‚Üí ‡∏ô‡πà‡∏≤‡∏à‡∏∞‡∏ú‡∏¥‡∏î

#### **B. ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥**
```python
# ‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø: lat 13.5-14.0, lon 100.3-100.8
BANGKOK_BOUNDS = {
    'lat_min': 13.5,
    'lat_max': 14.0,
    'lon_min': 100.3,
    'lon_max': 100.8
}

# ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏≠‡∏Å‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï
df = df[
    (df['latitude'] >= BANGKOK_BOUNDS['lat_min']) &
    (df['latitude'] <= BANGKOK_BOUNDS['lat_max']) &
    (df['longitude'] >= BANGKOK_BOUNDS['lon_min']) &
    (df['longitude'] <= BANGKOK_BOUNDS['lon_max'])
]
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏≠‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏®‡∏∂‡∏Å‡∏©‡∏≤ ‚Üí ‡∏•‡∏ö‡∏ó‡∏¥‡πâ‡∏á
- ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô GPS signal drift

#### **C. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥ (Duplicates)**
```python
# ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥ (‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)
df = df.drop_duplicates(
    subset=['timestamp', 'location_id'],
    keep='first'  # ‡πÄ‡∏Å‡πá‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å
)
```

### **2. ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏≤‡∏¢ (Missing Data)**

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≤‡∏á‡πÜ:**

#### **A. Forward Fill (‡πÄ‡∏ï‡∏¥‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤)**
```python
# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡πâ‡∏≤ (location_id, heading)
df['heading'] = df.groupby('location_id')['heading'].fillna(method='ffill')
```

**‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö:**
- ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏£‡∏ñ (‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ö‡πà‡∏≠‡∏¢)
- ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á

#### **B. Interpolation (‡πÅ‡∏ó‡∏£‡∏Å‡∏Ñ‡πà‡∏≤)**
```python
# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á (speed)
df['speed'] = df.groupby('location_id')['speed'].interpolate(
    method='linear'  # ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á
)
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
# ‡∏Å‡πà‡∏≠‡∏ô interpolate
time:  10:00  10:05  10:10  10:15  10:20
speed:  45    NaN    NaN    NaN    35

# ‡∏´‡∏•‡∏±‡∏á interpolate (linear)
time:  10:00  10:05  10:10  10:15  10:20
speed:  45    42.5   40.0   37.5   35
```

**‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì:**
```python
# Linear interpolation
value_at_10:05 = 45 + (35 - 45) * (1/4) = 42.5
value_at_10:10 = 45 + (35 - 45) * (2/4) = 40.0
value_at_10:15 = 45 + (35 - 45) * (3/4) = 37.5
```

#### **C. Mean/Median Imputation**
```python
# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡∏ô‡πâ‡∏≠‡∏¢
# ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô

# ‡πÄ‡∏ï‡∏¥‡∏°‡∏î‡πâ‡∏ß‡∏¢ mean ‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà
df['speed'] = df.groupby(['location_id', 'hour'])['speed'].transform(
    lambda x: x.fillna(x.mean())
)
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
# ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ó‡∏µ‡πà LOC001 ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 8:00-9:00 = 40 km/h
# ‡∏ñ‡πâ‡∏≤‡∏Ç‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‚Üí ‡πÄ‡∏ï‡∏¥‡∏° 40
```

### **3. Quality Filtering (‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û)**

```python
# ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á
QUALITY_THRESHOLD = 0.3

df = df[df['quality_score'] > QUALITY_THRESHOLD]
```

**Quality Score ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å:**
```python
def calculate_quality_score(row):
    score = 1.0
    
    # ‡∏•‡∏î‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô probes ‡∏ô‡πâ‡∏≠‡∏¢
    if row['count_probes'] < 5:
        score *= 0.7
    
    # ‡∏•‡∏î‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô‡∏°‡∏≤‡∏Å
    if row['speed_std'] > 20:
        score *= 0.8
    
    # ‡∏•‡∏î‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ñ‡πâ‡∏≤ GPS accuracy ‡∏ï‡πà‡∏≥
    if row['gps_accuracy'] > 50:  # meters
        score *= 0.6
    
    return score
```

---

## üîß Feature Engineering

### **1. Speed Features (‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß)**

```python
# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì statistics ‡∏à‡∏≤‡∏Å speed ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏ô‡∏∂‡πà‡∏á
# ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡∏∏‡∏Å 5 ‡∏ô‡∏≤‡∏ó‡∏µ ‚Üí aggregate ‡πÄ‡∏õ‡πá‡∏ô 1 ‡∏Ñ‡πà‡∏≤

aggregated = df.groupby(['location_id', 'time_window']).agg({
    'speed': ['mean', 'median', 'std', 'min', 'max']
})

# Features ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ:
features = {
    'mean_speed': 45.5,      # ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
    'median_speed': 42.0,    # ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏•‡∏≤‡∏á
    'speed_std': 5.2,        # ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏ö‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ö‡∏ô
    'min_speed': 35.0,       # ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î
    'max_speed': 60.0,       # ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    'speed_range': 25.0      # ‡∏û‡∏¥‡∏™‡∏±‡∏¢ (max - min)
}
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**

- **mean_speed:** ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ ‚Üí ‡∏ö‡∏≠‡∏Å‡∏™‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°
- **median_speed:** ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á ‚Üí ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏à‡∏≤‡∏Å outliers
- **speed_std:** ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô ‚Üí ‡∏ö‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£
  - std ‡∏ï‡πà‡∏≥ = ‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠
  - std ‡∏™‡∏π‡∏á = ‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô (stop-and-go)

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì:**
```python
speeds = [40, 42, 45, 48, 50, 38, 41]

# Mean
mean = sum(speeds) / len(speeds)
     = (40+42+45+48+50+38+41) / 7
     = 304 / 7
     = 43.43 km/h

# Median (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡πà‡∏≠‡∏ô: [38,40,41,42,45,48,50])
median = 42 km/h  # ‡∏ï‡∏±‡∏ß‡∏Å‡∏•‡∏≤‡∏á

# Standard Deviation
std = sqrt(Œ£(x - mean)¬≤ / n)
    = sqrt(((40-43.43)¬≤ + (42-43.43)¬≤ + ... + (41-43.43)¬≤) / 7)
    = sqrt(57.43 / 7)
    = 2.87 km/h
```

### **2. Temporal Features (‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏ß‡∏•‡∏≤)**

#### **A. Hour Encoding (Cyclic)**

**‡∏õ‡∏±‡∏ç‡∏´‡∏≤:**
```python
# ‚ùå ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
hour = 23  # 23:00
hour = 0   # 00:00

# 23 ‡πÅ‡∏•‡∏∞ 0 ‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 23 ‚Üí ‡∏ú‡∏¥‡∏î! ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô
```

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ: Sine/Cosine Encoding**
```python
# ‚úÖ ‡πÉ‡∏ä‡πâ sine/cosine
import numpy as np

def encode_hour(hour):
    # ‡πÅ‡∏õ‡∏•‡∏á hour (0-23) ‡πÄ‡∏õ‡πá‡∏ô angle (0-2œÄ)
    angle = 2 * np.pi * hour / 24
    
    hour_sin = np.sin(angle)
    hour_cos = np.cos(angle)
    
    return hour_sin, hour_cos
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì:**
```python
# Hour 0 (00:00)
angle = 2œÄ * 0 / 24 = 0
sin(0) = 0.0
cos(0) = 1.0
‚Üí (0.0, 1.0)

# Hour 6 (06:00)
angle = 2œÄ * 6 / 24 = œÄ/2
sin(œÄ/2) = 1.0
cos(œÄ/2) = 0.0
‚Üí (1.0, 0.0)

# Hour 12 (12:00)
angle = 2œÄ * 12 / 24 = œÄ
sin(œÄ) = 0.0
cos(œÄ) = -1.0
‚Üí (0.0, -1.0)

# Hour 18 (18:00)
angle = 2œÄ * 18 / 24 = 3œÄ/2
sin(3œÄ/2) = -1.0
cos(3œÄ/2) = 0.0
‚Üí (-1.0, 0.0)

# Hour 23 (23:00)
angle = 2œÄ * 23 / 24 = 23œÄ/12
sin(23œÄ/12) ‚âà -0.26
cos(23œÄ/12) ‚âà 0.97
‚Üí (-0.26, 0.97)
```

**‡∏ó‡∏≥‡πÑ‡∏°‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô?**
```python
# Distance between 23:00 and 00:00
distance = sqrt((0.0 - (-0.26))¬≤ + (1.0 - 0.97)¬≤)
         = sqrt(0.26¬≤ + 0.03¬≤)
         = sqrt(0.068 + 0.001)
         = 0.26  # ‡πÉ‡∏Å‡∏•‡πâ! ‚úÖ

# ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
distance = |0 - 23| = 23  # ‡πÑ‡∏Å‡∏•! ‚ùå
```

#### **B. Day of Week Encoding**

```python
def encode_day_of_week(dow):
    # dow: 0=Monday, 6=Sunday
    angle = 2 * np.pi * dow / 7
    
    dow_sin = np.sin(angle)
    dow_cos = np.cos(angle)
    
    return dow_sin, dow_cos
```

#### **C. Weekend Flag**

```python
# Binary feature
is_weekend = 1 if dow >= 5 else 0  # 5=Sat, 6=Sun
```

### **3. Count Features (‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö)**

```python
# ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô probe vehicles
count_probes = len(speeds_in_window)

# ‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô
confidence = min(count_probes / 10, 1.0)
# ‡∏ñ‡πâ‡∏≤ probes < 10 ‚Üí confidence ‡∏ï‡πà‡∏≥
```

### **4. Congestion Labels (‡∏õ‡πâ‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏≠‡∏≠‡∏±‡∏î)**

**‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß:**

```python
def classify_congestion(mean_speed):
    if mean_speed < 20:
        return 'gridlock'      # ‡∏£‡∏ñ‡∏ï‡∏¥‡∏î‡∏°‡∏≤‡∏Å (0)
    elif mean_speed < 40:
        return 'congested'     # ‡∏£‡∏ñ‡∏ï‡∏¥‡∏î‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á (1)
    elif mean_speed < 60:
        return 'moderate'      # ‡∏£‡∏ñ‡∏û‡∏≠‡∏™‡∏∞‡∏î‡∏ß‡∏Å (2)
    else:
        return 'free_flow'     # ‡∏£‡∏ñ‡πÑ‡∏´‡∏•‡∏™‡∏∞‡∏î‡∏ß‡∏Å (3)
```

**Mapping to numbers:**
```python
congestion_map = {
    'gridlock': 0,
    'congested': 1,
    'moderate': 2,
    'free_flow': 3
}
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- **Gridlock (0-20 km/h):** ‡∏£‡∏ñ‡∏ï‡∏¥‡∏î‡∏´‡∏ô‡∏±‡∏Å ‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡πâ‡∏≤‡∏°‡∏≤‡∏Å
- **Congested (20-40 km/h):** ‡∏£‡∏ñ‡∏ï‡∏¥‡∏î ‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡πâ‡∏≤
- **Moderate (40-60 km/h):** ‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á
- **Free Flow (>60 km/h):** ‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£‡∏™‡∏∞‡∏î‡∏ß‡∏Å

### **5. Rush Hour Labels (‡∏õ‡πâ‡∏≤‡∏¢‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô)**

```python
def is_rush_hour(hour, dow):
    # ‡∏ß‡∏±‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ (Mon-Fri)
    if dow < 5:
        # ‡πÄ‡∏ä‡πâ‡∏≤ 7:00-9:00 ‡∏´‡∏£‡∏∑‡∏≠ ‡πÄ‡∏¢‡πá‡∏ô 17:00-19:00
        if (7 <= hour < 9) or (17 <= hour < 19):
            return 1  # Rush hour
    
    return 0  # Non-rush hour
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- **Rush hour:** ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô (‡∏Ñ‡∏ô‡πÑ‡∏õ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô/‡∏Å‡∏•‡∏±‡∏ö‡∏ö‡πâ‡∏≤‡∏ô)
- **Non-rush hour:** ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥

---

## üìè ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á

### **Haversine Formula (‡∏™‡∏π‡∏ï‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏ö‡∏ô‡πÇ‡∏•‡∏Å)**

**‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** ‡∏û‡∏¥‡∏Å‡∏±‡∏î latitude/longitude ‡∏ö‡∏ô‡πÇ‡∏•‡∏Å‡∏Å‡∏•‡∏° ‚Üí ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ Euclidean distance ‡πÑ‡∏î‡πâ

**‡∏™‡∏π‡∏ï‡∏£ Haversine:**

```python
def haversine_distance(lat1, lon1, lat2, lon2):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏ö‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ú‡∏¥‡∏ß‡πÇ‡∏•‡∏Å
    
    Parameters:
        lat1, lon1: ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà 1 (degrees)
        lat2, lon2: ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà 2 (degrees)
    
    Returns:
        distance: ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á (kilometers)
    """
    # Radius ‡∏Ç‡∏≠‡∏á‡πÇ‡∏•‡∏Å (km)
    R = 6371.0
    
    # ‡πÅ‡∏õ‡∏•‡∏á degrees ‡πÄ‡∏õ‡πá‡∏ô radians
    lat1_rad = np.radians(lat1)
    lon1_rad = np.radians(lon1)
    lat2_rad = np.radians(lat2)
    lon2_rad = np.radians(lon2)
    
    # ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á
    dlat = lat2_rad - lat1_rad
    dlon = lon2_rad - lon1_rad
    
    # Haversine formula
    a = np.sin(dlat/2)**2 + \
        np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon/2)**2
    
    c = 2 * np.arcsin(np.sqrt(a))
    
    # ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á
    distance = R * c
    
    return distance
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì:**

```python
# ‡∏à‡∏∏‡∏î A: MBK Center
lat1 = 13.7447
lon1 = 100.5298

# ‡∏à‡∏∏‡∏î B: Siam Paragon
lat2 = 13.7467
lon2 = 100.5343

# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
distance = haversine_distance(lat1, lon1, lat2, lon2)
print(f"Distance: {distance:.3f} km")
# Output: Distance: 0.523 km (‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 500 ‡πÄ‡∏°‡∏ï‡∏£)
```

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î:**

```python
# Step 1: ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô radians
lat1_rad = 13.7447 * œÄ/180 = 0.2399
lon1_rad = 100.5298 * œÄ/180 = 1.7544
lat2_rad = 13.7467 * œÄ/180 = 0.2400
lon2_rad = 100.5343 * œÄ/180 = 1.7552

# Step 2: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á
dlat = 0.2400 - 0.2399 = 0.0001
dlon = 1.7552 - 1.7544 = 0.0008

# Step 3: Haversine formula
a = sin¬≤(dlat/2) + cos(lat1_rad) * cos(lat2_rad) * sin¬≤(dlon/2)
  = sin¬≤(0.00005) + cos(0.2399) * cos(0.2400) * sin¬≤(0.0004)
  = 0.0000000025 + 0.9715 * 0.9715 * 0.00000016
  = 0.0000000025 + 0.0000001508
  = 0.0000001533

# Step 4: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì c
c = 2 * arcsin(sqrt(0.0000001533))
  = 2 * arcsin(0.000392)
  = 2 * 0.000392
  = 0.000784

# Step 5: ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á
distance = 6371 * 0.000784
         = 4.99 km
         ‚âà 0.5 km ‚úÖ
```

**‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Haversine?**

```python
# ‚ùå Euclidean distance (‡∏ú‡∏¥‡∏î!)
distance = sqrt((lat2-lat1)¬≤ + (lon2-lon1)¬≤)
         = sqrt((0.002)¬≤ + (0.0045)¬≤)
         = 0.0049  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢!

# ‚úÖ Haversine (‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á!)
distance = 0.523 km  # ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á‡∏ö‡∏ô‡πÇ‡∏•‡∏Å
```

### **‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Distance Matrix**

```python
# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
locations = 217  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà

distance_matrix = np.zeros((locations, locations))

for i in range(locations):
    for j in range(locations):
        if i != j:
            distance_matrix[i][j] = haversine_distance(
                lat[i], lon[i],
                lat[j], lon[j]
            )

# distance_matrix[i][j] = ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà i ‡πÑ‡∏õ‡∏¢‡∏±‡∏á j
```

**‡πÉ‡∏ä‡πâ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£?**
- ‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á (neighbors)
- ‡∏™‡∏£‡πâ‡∏≤‡∏á graph edges
- ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á

---

## üìä ‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

### **Train/Validation/Test Split**

```python
from sklearn.model_selection import train_test_split

# Total samples
n_samples = len(data)

# Split ratio: 70% train, 15% val, 15% test
train_ratio = 0.70
val_ratio = 0.15
test_ratio = 0.15

# Step 1: ‡πÅ‡∏ö‡πà‡∏á train + val vs test
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y,
    test_size=test_ratio,
    random_state=42,
    stratify=y  # ‡πÄ‡∏Å‡πá‡∏ö‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô labels ‡πÄ‡∏ó‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°
)

# Step 2: ‡πÅ‡∏ö‡πà‡∏á train vs val
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp,
    test_size=val_ratio / (train_ratio + val_ratio),
    random_state=42,
    stratify=y_temp
)

print(f"Train: {len(X_train)} samples")
print(f"Val: {len(X_val)} samples")
print(f"Test: {len(X_test)} samples")
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```
Total: 2398 samples

Train: 1678 samples (70%)
Val:   359 samples  (15%)
Test:  361 samples  (15%)
```

**‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏ö‡πà‡∏á?**

- **Train Set:** ‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ)
- **Validation Set:** ‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏±‡∏ö hyperparameters (‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô ‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à)
- **Test Set:** ‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏à‡∏£‡∏¥‡∏á (‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏´‡πá‡∏ô)

**Stratify ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?**

```python
# ‚ùå ‡πÑ‡∏°‡πà stratify
train_labels = [0, 0, 0, 1, 1]  # 60% class 0
test_labels = [2, 2, 3, 3, 3]   # 0% class 0 ‚Üí ‡πÑ‡∏°‡πà‡∏™‡∏°‡∏î‡∏∏‡∏•!

# ‚úÖ Stratify
# ‡πÄ‡∏Å‡πá‡∏ö‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°
original = [0:40%, 1:30%, 2:20%, 3:10%]
train = [0:40%, 1:30%, 2:20%, 3:10%]  # ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏° ‚úÖ
test = [0:40%, 1:30%, 2:20%, 3:10%]   # ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏° ‚úÖ
```

---

## üîÑ Data Augmentation

### **1. Noise Injection (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏£‡∏ö‡∏Å‡∏ß‡∏ô)**

```python
def add_noise(X, noise_level=0.01):
    """
    ‡πÄ‡∏û‡∏¥‡πà‡∏° Gaussian noise
    
    Parameters:
        X: input data
        noise_level: ‡∏£‡∏∞‡∏î‡∏±‡∏ö noise (std)
    
    Returns:
        X_noisy: data + noise
    """
    noise = np.random.randn(*X.shape) * noise_level
    X_noisy = X + noise
    
    return X_noisy
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
# Original
X = [45.5, 42.0, 5.2, 25, 0.85, ...]

# Add noise (1%)
noise = [0.3, -0.2, 0.1, 0.4, -0.01, ...]
X_noisy = [45.8, 41.8, 5.3, 25.4, 0.84, ...]

# ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ ‡πÅ‡∏ï‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• robust
```

**‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ?**
- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏°‡∏µ noise
- ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô
- ‡∏•‡∏î overfitting

### **2. Feature Scaling**

**Standardization (Z-score normalization):**

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

# Fit on training data
scaler.fit(X_train)

# Transform all sets
X_train_scaled = scaler.transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)
```

**‡∏™‡∏π‡∏ï‡∏£:**
```python
X_scaled = (X - mean) / std
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
mean_speed = [20, 30, 40, 50, 60]

# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
mean = 40
std = 14.14

# Standardize
scaled = [(20-40)/14.14, (30-40)/14.14, (40-40)/14.14, 
          (50-40)/14.14, (60-40)/14.14]
       = [-1.41, -0.71, 0.0, 0.71, 1.41]

# Mean ‚âà 0, Std ‚âà 1
```

**‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á scale?**

```python
# ‚ùå ‡πÑ‡∏°‡πà scale
feature1 = mean_speed (0-120)
feature2 = is_weekend (0-1)

# Neural network ‡∏à‡∏∞ "‡∏™‡∏ô‡πÉ‡∏à" feature1 ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤
# ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤

# ‚úÖ Scale
feature1_scaled = (-2 to 2)
feature2_scaled = (-1 to 1)

# ‡∏ó‡∏∏‡∏Å features ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô
```

---

## üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£

### **Pipeline ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:**

```
1. Load Raw Data
   ‚Üì
2. Clean Data (remove outliers, duplicates)
   ‚Üì
3. Handle Missing Values (interpolate, fill)
   ‚Üì
4. Feature Engineering
   ‚îú‚îÄ Speed features (mean, median, std)
   ‚îú‚îÄ Temporal features (hour_sin/cos, dow_sin/cos)
   ‚îú‚îÄ Count features
   ‚îî‚îÄ Quality score
   ‚Üì
5. Create Labels
   ‚îú‚îÄ Congestion levels (0-3)
   ‚îî‚îÄ Rush hour (0-1)
   ‚Üì
6. Calculate Distances (Haversine)
   ‚Üì
7. Train/Val/Test Split (70/15/15)
   ‚Üì
8. Feature Scaling (Standardization)
   ‚Üì
9. Data Augmentation (noise injection)
   ‚Üì
10. Ready for Training!
```

### **‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏™‡∏£‡∏∏‡∏õ:**

```python
# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö
Raw data: ~100,000 GPS records/day

# ‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
Clean data: ~80,000 records/day

# ‡∏´‡∏•‡∏±‡∏á aggregate (5-min windows)
Aggregated: ~2,400 samples/day

# ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
Final dataset: ~2,398 samples

# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
Train: 1,678 samples (70%)
Val:   359 samples  (15%)
Test:  361 samples  (15%)
```

---

## üéØ ‡∏™‡∏£‡∏∏‡∏õ

‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢:

1. **‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î:** ‡∏•‡∏ö outliers, duplicates, missing values
2. **Feature Engineering:** ‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå
3. **Temporal Encoding:** ‡πÉ‡∏ä‡πâ sine/cosine ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤
4. **Label Creation:** ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å congestion ‡πÅ‡∏•‡∏∞ rush hour
5. **Distance Calculation:** ‡πÉ‡∏ä‡πâ Haversine formula
6. **Data Split:** ‡πÅ‡∏ö‡πà‡∏á train/val/test ‡πÅ‡∏ö‡∏ö stratified
7. **Scaling:** Standardization
8. **Augmentation:** ‡πÄ‡∏û‡∏¥‡πà‡∏° noise ‡πÄ‡∏û‡∏∑‡πà‡∏≠ robustness

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:** ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∞‡∏≠‡∏≤‡∏î ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•!

‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: [TRAINING_GUIDE_TH.md](./TRAINING_GUIDE_TH.md)
