# üìò ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÇ‡∏Ñ‡πâ‡∏î: graph_constructor.py

## üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ü‡∏•‡πå

- **‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå:** `src/utils/graph_constructor.py`
- **‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:** ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏ñ‡∏ô‡∏ô
- **‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î:** ~407 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
- **‡∏†‡∏≤‡∏©‡∏≤:** Python + NetworkX + PyTorch Geometric

---

## üéØ ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°

‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á **‡∏Å‡∏£‡∏≤‡∏ü‡∏à‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏ñ‡∏ô‡∏ô** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• GNN ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏î‡πâ

### **Pipeline:**
```
Road Network (OSM) ‚Üí Graph Construction ‚Üí PyTorch Geometric Data
    ‚Üì
Nodes = ‡∏à‡∏∏‡∏î‡∏ï‡∏±‡∏î (intersections)
Edges = ‡∏ñ‡∏ô‡∏ô (road segments)
Features = ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£
```

---

## üìÇ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏•‡∏≤‡∏™ GraphConstructor

```python
class GraphConstructor:
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏ñ‡∏ô‡∏ô
    """
    
    # Constructor
    __init__(road_network)
    
    # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü
    build_road_graph()
    create_adjacency_matrix()
    
    # 2. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ neighbors
    find_k_nearest_neighbors()
    compute_haversine_distance()
    
    # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á PyTorch Geometric Data
    create_pytorch_geometric_data()
    prepare_for_training()
    
    # 4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å/‡πÇ‡∏´‡∏•‡∏î
    save_graph()
    load_graph()
    
    # 5. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    get_graph_statistics()
    visualize_graph()
```

---

## 1Ô∏è‚É£ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü

### **build_road_graph() - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏à‡∏≤‡∏Å‡∏ñ‡∏ô‡∏ô**

```python
def build_road_graph(self, connection_threshold: float = 0.001) -> nx.Graph:
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á NetworkX Graph ‡∏à‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏ñ‡∏ô‡∏ô
    
    Args:
        connection_threshold: ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏∏‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô (degrees)
                             0.001¬∞ ‚âà 110 ‡πÄ‡∏°‡∏ï‡∏£
    
    Returns:
        NetworkX Graph object
    
    ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô:
        1. ‡πÅ‡∏¢‡∏Å‡∏à‡∏∏‡∏î‡∏õ‡∏•‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏™‡πâ‡∏ô‡∏ñ‡∏ô‡∏ô (endpoints)
        2. ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô intersections (‡∏à‡∏∏‡∏î‡∏ï‡∏±‡∏î)
        3. ‡∏™‡∏£‡πâ‡∏≤‡∏á nodes = intersections
        4. ‡∏™‡∏£‡πâ‡∏≤‡∏á edges = ‡∏ñ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á intersections
    """
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:**

#### **Step 1: ‡πÅ‡∏¢‡∏Å‡∏à‡∏∏‡∏î‡∏õ‡∏•‡∏≤‡∏¢‡∏ñ‡∏ô‡∏ô**
```
Road 1: A ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ B
Road 2: B ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ C
Road 3: A ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ D

Endpoints:
Road 1: (A, B)
Road 2: (B, C)
Road 3: (A, D)
```

#### **Step 2: ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πá‡∏ô Intersections**
```python
# ‡∏à‡∏∏‡∏î A ‡πÅ‡∏•‡∏∞ A ‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô < threshold ‚Üí ‡πÄ‡∏õ‡πá‡∏ô intersection ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
# ‡∏à‡∏∏‡∏î B ‡πÅ‡∏•‡∏∞ B ‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô < threshold ‚Üí ‡πÄ‡∏õ‡πá‡∏ô intersection ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô

Intersections:
  Intersection 0: ‡∏à‡∏∏‡∏î A (‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° Road 1, 3)
  Intersection 1: ‡∏à‡∏∏‡∏î B (‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° Road 1, 2)
  Intersection 2: ‡∏à‡∏∏‡∏î C (‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° Road 2)
  Intersection 3: ‡∏à‡∏∏‡∏î D (‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° Road 3)
```

#### **Step 3: ‡∏™‡∏£‡πâ‡∏≤‡∏á Graph**
```python
G = nx.Graph()

# Add nodes (intersections)
G.add_node(0, pos=(13.7563, 100.5018), num_connections=2)
G.add_node(1, pos=(13.7565, 100.5020), num_connections=2)
G.add_node(2, pos=(13.7567, 100.5022), num_connections=1)
G.add_node(3, pos=(13.7560, 100.5015), num_connections=1)

# Add edges (roads)
G.add_edge(0, 1, edge_id='ROAD_1', length_km=0.25)
G.add_edge(1, 2, edge_id='ROAD_2', length_km=0.30)
G.add_edge(0, 3, edge_id='ROAD_3', length_km=0.20)
```

**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:**
```
Graph:
  (0) ---- ROAD_1 ---- (1)
   |                    |
ROAD_3               ROAD_2
   |                    |
  (3)                  (2)
```

---

### **create_adjacency_matrix() - ‡∏™‡∏£‡πâ‡∏≤‡∏á Adjacency Matrix**

```python
def create_adjacency_matrix(self, normalize: bool = True) -> np.ndarray:
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á adjacency matrix ‡∏à‡∏≤‡∏Å‡∏Å‡∏£‡∏≤‡∏ü
    
    Args:
        normalize: normalize ‡πÅ‡∏ñ‡∏ß‡πÉ‡∏´‡πâ‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô 1
    
    Returns:
        Adjacency matrix shape (num_nodes, num_nodes)
    
    Normalization:
        1. ‡πÄ‡∏û‡∏¥‡πà‡∏° self-loops (diagonal = 1)
        2. Normalize ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏ñ‡∏ß: A_ij = A_ij / sum(A_i)
    """
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á adjacency matrix
    adj_matrix = nx.adjacency_matrix(self.graph).toarray()
    
    # ‡πÄ‡∏ä‡πà‡∏ô:
    # [[0, 1, 0, 1],   # Node 0 ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Å‡∏±‡∏ö 1, 3
    #  [1, 0, 1, 0],   # Node 1 ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Å‡∏±‡∏ö 0, 2
    #  [0, 1, 0, 0],   # Node 2 ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Å‡∏±‡∏ö 1
    #  [1, 0, 0, 0]]   # Node 3 ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Å‡∏±‡∏ö 0
    
    if normalize:
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° self-loops
        adj_matrix += np.eye(adj_matrix.shape[0])
        
        # Row normalization
        row_sums = adj_matrix.sum(axis=1, keepdims=True)
        adj_matrix = adj_matrix / row_sums
    
    return adj_matrix
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
# Before normalization:
[[0, 1, 0, 1],
 [1, 0, 1, 0],
 [0, 1, 0, 0],
 [1, 0, 0, 0]]

# After adding self-loops:
[[1, 1, 0, 1],   # sum = 3
 [1, 1, 1, 0],   # sum = 3
 [0, 1, 1, 0],   # sum = 2
 [1, 0, 0, 1]]   # sum = 2

# After normalization:
[[0.33, 0.33, 0.00, 0.33],   # ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏ñ‡∏ß‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô 1
 [0.33, 0.33, 0.33, 0.00],
 [0.00, 0.50, 0.50, 0.00],
 [0.50, 0.00, 0.00, 0.50]]
```

---

## 2Ô∏è‚É£ ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Neighbors

### **find_k_nearest_neighbors() - ‡∏´‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ö‡πâ‡∏≤‡∏ô K ‡∏ï‡∏±‡∏ß**

```python
def find_k_nearest_neighbors(self, locations: pd.DataFrame, 
                             k: int = 5) -> Dict:
    """
    ‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î K ‡∏ï‡∏±‡∏ß
    
    Args:
        locations: DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ (latitude, longitude)
        k: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ö‡πâ‡∏≤‡∏ô
    
    Returns:
        dict: {location_id: [neighbor_ids]}
    """
    
    neighbors = {}
    
    for idx, row in locations.iterrows():
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        distances = []
        for idx2, row2 in locations.iterrows():
            if idx != idx2:
                dist = self.compute_haversine_distance(
                    row['latitude'], row['longitude'],
                    row2['latitude'], row2['longitude']
                )
                distances.append((idx2, dist))
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á
        distances.sort(key=lambda x: x[1])
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å k ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å
        neighbors[idx] = [loc_id for loc_id, _ in distances[:k]]
    
    return neighbors
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
locations = pd.DataFrame({
    'id': ['A', 'B', 'C', 'D', 'E'],
    'latitude': [13.75, 13.76, 13.74, 13.77, 13.73],
    'longitude': [100.50, 100.51, 100.49, 100.52, 100.48]
})

neighbors = find_k_nearest_neighbors(locations, k=2)

# Output:
{
    'A': ['B', 'C'],  # A ‡πÉ‡∏Å‡∏•‡πâ B ‡πÅ‡∏•‡∏∞ C ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    'B': ['A', 'D'],  # B ‡πÉ‡∏Å‡∏•‡πâ A ‡πÅ‡∏•‡∏∞ D ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    'C': ['A', 'E'],
    'D': ['B', 'A'],
    'E': ['C', 'A']
}
```

---

### **compute_haversine_distance() - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á**

```python
def compute_haversine_distance(self, lat1, lon1, lat2, lon2) -> float:
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏ö‡∏ô‡πÇ‡∏•‡∏Å (Great Circle Distance)
    
    ‡∏™‡∏π‡∏ï‡∏£ Haversine:
        a = sin¬≤(Œîlat/2) + cos(lat1)√ócos(lat2)√ósin¬≤(Œîlon/2)
        c = 2 √ó arcsin(‚àöa)
        distance = R √ó c  (R = 6371 km)
    """
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô radians
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ú‡∏•‡∏ï‡πà‡∏≤‡∏á
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    
    # ‡∏™‡∏π‡∏ï‡∏£ Haversine
    a = np.sin(dlat/2)**2 + \
        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
    c = 2 * np.arcsin(np.sqrt(a))
    
    # ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á (km)
    R = 6371
    distance = R * c
    
    return distance
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
# Siam Square ‚Üí MBK Center
distance = compute_haversine_distance(
    13.7465, 100.5326,  # Siam
    13.7443, 100.5300   # MBK
)
print(f"Distance: {distance:.3f} km")
# Output: Distance: 0.323 km
```

---

## 3Ô∏è‚É£ ‡∏™‡∏£‡πâ‡∏≤‡∏á PyTorch Geometric Data

### **create_pytorch_geometric_data() - ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô PyG Data**

```python
def create_pytorch_geometric_data(self, features_df: pd.DataFrame,
                                  labels_df: pd.DataFrame) -> Data:
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á PyTorch Geometric Data object
    
    Args:
        features_df: DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ features (num_nodes, num_features)
        labels_df: DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ labels
    
    Returns:
        PyTorch Geometric Data object
    """
    
    # Node features
    x = torch.FloatTensor(features_df.values)  # [num_nodes, num_features]
    
    # Labels
    y_congestion = torch.LongTensor(labels_df['congestion_label'].values)
    y_rush_hour = torch.LongTensor(labels_df['rush_hour_label'].values)
    
    # Edge index
    edge_list = []
    for node1, node2 in self.graph.edges():
        node1_idx = self.node_mapping[node1]
        node2_idx = self.node_mapping[node2]
        edge_list.append([node1_idx, node2_idx])
        edge_list.append([node2_idx, node1_idx])  # Undirected
    
    edge_index = torch.LongTensor(edge_list).t()  # [2, num_edges]
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Data object
    data = Data(
        x=x,
        edge_index=edge_index,
        y_congestion=y_congestion,
        y_rush_hour=y_rush_hour
    )
    
    return data
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
# Features (217 nodes, 10 features)
features_df = pd.DataFrame({
    'speed_mean': [45.2, 38.5, ...],
    'speed_std': [5.1, 7.2, ...],
    'hour_sin': [0.707, 0.707, ...],
    ...  # 10 features total
})

# Labels
labels_df = pd.DataFrame({
    'congestion_label': [2, 1, 3, ...],  # 0-3
    'rush_hour_label': [1, 1, 0, ...]    # 0-1
})

# ‡∏™‡∏£‡πâ‡∏≤‡∏á PyG Data
data = create_pytorch_geometric_data(features_df, labels_df)

print(data)
# Output:
# Data(x=[217, 10], edge_index=[2, 1234], 
#      y_congestion=[217], y_rush_hour=[217])
```

---

### **prepare_for_training() - ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ó‡∏£‡∏ô**

```python
def prepare_for_training(self, processed_df: pd.DataFrame,
                        train_split: float = 0.8) -> Tuple:
    """
    ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô train/val/test
    
    Returns:
        (train_data, val_data, test_data)
    """
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á PyG Data
    data = self.create_pytorch_geometric_data(
        processed_df[feature_columns],
        processed_df[label_columns]
    )
    
    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    num_nodes = data.x.shape[0]
    indices = np.random.permutation(num_nodes)
    
    train_size = int(num_nodes * 0.7)
    val_size = int(num_nodes * 0.15)
    
    train_mask = torch.zeros(num_nodes, dtype=torch.bool)
    val_mask = torch.zeros(num_nodes, dtype=torch.bool)
    test_mask = torch.zeros(num_nodes, dtype=torch.bool)
    
    train_mask[indices[:train_size]] = True
    val_mask[indices[train_size:train_size+val_size]] = True
    test_mask[indices[train_size+val_size:]] = True
    
    data.train_mask = train_mask
    data.val_mask = val_mask
    data.test_mask = test_mask
    
    return data
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
data = prepare_for_training(processed_df, train_split=0.7)

print(f"Total nodes: {data.x.shape[0]}")
print(f"Train nodes: {data.train_mask.sum().item()}")
print(f"Val nodes: {data.val_mask.sum().item()}")
print(f"Test nodes: {data.test_mask.sum().item()}")

# Output:
# Total nodes: 217
# Train nodes: 152 (70%)
# Val nodes: 33 (15%)
# Test nodes: 32 (15%)
```

---

## 4Ô∏è‚É£ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å/‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏£‡∏≤‡∏ü

### **save_graph() - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏£‡∏≤‡∏ü**

```python
def save_graph(self, filepath: str):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"""
    
    graph_data = {
        'graph': self.graph,
        'node_mapping': self.node_mapping,
        'edge_mapping': self.edge_mapping,
        'adjacency_matrix': self.adjacency_matrix
    }
    
    with open(filepath, 'wb') as f:
        pickle.dump(graph_data, f)
    
    print(f"Graph saved to {filepath}")
```

### **load_graph() - ‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏£‡∏≤‡∏ü**

```python
def load_graph(self, filepath: str):
    """‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏£‡∏≤‡∏ü‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ"""
    
    with open(filepath, 'rb') as f:
        graph_data = pickle.load(f)
    
    self.graph = graph_data['graph']
    self.node_mapping = graph_data['node_mapping']
    self.edge_mapping = graph_data['edge_mapping']
    self.adjacency_matrix = graph_data['adjacency_matrix']
    
    print(f"Graph loaded from {filepath}")
```

---

## 5Ô∏è‚É£ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏£‡∏≤‡∏ü

### **get_graph_statistics() - ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏£‡∏≤‡∏ü**

```python
def get_graph_statistics(self) -> Dict:
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏Å‡∏£‡∏≤‡∏ü
    """
    
    stats = {
        'num_nodes': self.graph.number_of_nodes(),
        'num_edges': self.graph.number_of_edges(),
        'avg_degree': np.mean([d for _, d in self.graph.degree()]),
        'density': nx.density(self.graph),
        'num_components': nx.number_connected_components(self.graph),
        'diameter': nx.diameter(self.graph) if nx.is_connected(self.graph) else None,
        'avg_clustering': nx.average_clustering(self.graph)
    }
    
    return stats
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
stats = graph_constructor.get_graph_statistics()

print(stats)
# Output:
# {
#     'num_nodes': 217,
#     'num_edges': 542,
#     'avg_degree': 4.99,
#     'density': 0.023,
#     'num_components': 1,
#     'diameter': 12,
#     'avg_clustering': 0.15
# }
```

---

## üí° ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

```python
import geopandas as gpd
import pandas as pd

# 1. ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏ñ‡∏ô‡∏ô
road_network = gpd.read_file("Data/hotosm_tha_roads_lines_gpkg/roads.gpkg")

# 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á GraphConstructor
graph_constructor = GraphConstructor(road_network)

# 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü
G = graph_constructor.build_road_graph(connection_threshold=0.001)
print(f"Created graph with {G.number_of_nodes()} nodes")

# 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á adjacency matrix
adj_matrix = graph_constructor.create_adjacency_matrix(normalize=True)
print(f"Adjacency matrix shape: {adj_matrix.shape}")

# 5. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß
processed_df = pd.read_pickle("outputs/processed_data.pkl")

# 6. ‡∏™‡∏£‡πâ‡∏≤‡∏á PyTorch Geometric Data
data = graph_constructor.prepare_for_training(
    processed_df,
    train_split=0.7
)

print(f"PyG Data: {data}")
print(f"  Nodes: {data.x.shape}")
print(f"  Edges: {data.edge_index.shape}")
print(f"  Train: {data.train_mask.sum()}")
print(f"  Val: {data.val_mask.sum()}")
print(f"  Test: {data.test_mask.sum()}")

# 7. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏£‡∏≤‡∏ü
graph_constructor.save_graph("outputs/road_graph.pkl")

# 8. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏£‡∏≤‡∏ü
stats = graph_constructor.get_graph_statistics()
for key, value in stats.items():
    print(f"  {key}: {value}")

# 9. ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• GNN
from src.models.multi_task_gnn import MultiTaskTrafficGNN

model = MultiTaskTrafficGNN(num_features=10, hidden_dim=64)
outputs = model(data)

print(f"Congestion predictions: {outputs['congestion_logits'].shape}")
print(f"Rush hour predictions: {outputs['rush_hour_logits'].shape}")
```

---

## üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏£‡∏≤‡∏ü

### **‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏ñ‡∏ô‡∏ô‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û:**

```
Nodes (Intersections): 217
Edges (Road Segments): 542
Average Degree: 4.99
Graph Density: 0.023
Connected Components: 1
Diameter: 12 hops
Average Clustering: 0.15
```

### **Degree Distribution:**
```python
degrees = [d for _, d in G.degree()]

# ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
min_degree: 2
max_degree: 12
mean_degree: 4.99
median_degree: 5

# Distribution:
Degree 2: 15 nodes (7%)
Degree 3: 42 nodes (19%)
Degree 4: 65 nodes (30%)
Degree 5: 58 nodes (27%)
Degree 6+: 37 nodes (17%)
```

---

## üéì ‡∏™‡∏£‡∏∏‡∏õ

### **Key Concepts:**

1. **Graph Construction:**
   - Nodes = ‡∏à‡∏∏‡∏î‡∏ï‡∏±‡∏î‡∏ñ‡∏ô‡∏ô (intersections)
   - Edges = ‡πÄ‡∏™‡πâ‡∏ô‡∏ñ‡∏ô‡∏ô (road segments)
   - ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡∏≤‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á

2. **Adjacency Matrix:**
   - ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠
   - Normalize ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GNN
   - Sparse matrix (‡πÑ‡∏°‡πà‡∏´‡∏ô‡∏≤‡πÅ‡∏ô‡πà‡∏ô)

3. **Neighbor Finding:**
   - K-nearest neighbors
   - Haversine distance
   - Spatial proximity

4. **PyTorch Geometric:**
   - Data object ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GNN
   - edge_index format
   - train/val/test masks

---

**‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠:** 5 ‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏° 2025  
**‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô:** 1.0  
**‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô:** Traffic GNN Classification Team
