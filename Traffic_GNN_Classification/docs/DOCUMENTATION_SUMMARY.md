# üéì ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì

‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏ú‡∏°‡πÑ‡∏î‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢**‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á**‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö

---

## üìö ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì

### **1. üìñ README_TH.md - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (‡∏´‡∏ô‡∏≤ 200+ ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î)**

**Path:** `docs/README_TH.md`

**‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤:**
- ‚úÖ ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ - ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£
- ‚úÖ ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ - PyTorch, GNN, Streamlit (‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏£‡∏ö)
- ‚úÖ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ - ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£
- ‚úÖ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á - ‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô
- ‚úÖ ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô - ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•, ‡πÄ‡∏õ‡∏¥‡∏î Dashboard
- ‚úÖ ‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ - ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥ (Training, Epoch, Loss, etc.)

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
```python
# ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤ Epoch ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£
Epoch = ‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô = ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î 1 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á

# ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤ Batch ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£
Batch = ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• = ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏•‡∏∞‡∏Å‡∏µ‡πà‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
```

---

### **2. üî¨ TECHNICAL_DETAILS_TH.md - ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ (‡∏´‡∏ô‡∏≤ 500+ ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î)**

**Path:** `docs/TECHNICAL_DETAILS_TH.md`

**‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤:**
- ‚úÖ **Graph Neural Network ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£** - ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
- ‚úÖ **‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏•**:
  - SimpleMultiTaskGNN - ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
  - EnhancedGNNModel - ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á
  - ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ó‡∏∏‡∏Å layer, ‡∏ó‡∏∏‡∏Å function
- ‚úÖ **‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•**:
  - Forward Pass - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ (‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)
  - Backward Pass - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì gradient (‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)
  - Matrix multiplication - ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô
- ‚úÖ **Loss Functions** - Cross-Entropy ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏π‡∏ï‡∏£
- ‚úÖ **Optimization**:
  - AdamW Optimizer - ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£
  - Learning Rate Scheduler - ‡∏•‡∏î LR ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
  - Gradient Clipping - ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô exploding gradients
  - Early Stopping - ‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠ overfitting
- ‚úÖ **‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á**:
  - Batch Normalization - ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
  - Residual Connections - ‡πÅ‡∏Å‡πâ vanishing gradient
  - Attention Mechanism - ‡πÇ‡∏°‡πÄ‡∏î‡∏• "‡∏™‡∏ô‡πÉ‡∏à" ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
  - Dropout - ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô overfitting

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
```python
# ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ ReLU ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏£‡∏≤‡∏ü
ReLU(x) = max(0, x)

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:
x = [-2, -1, 0, 1, 2]
ReLU(x) = [0, 0, 0, 1, 2]  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡πà‡∏≤‡∏ï‡∏¥‡∏î‡∏•‡∏ö‡πÄ‡∏õ‡πá‡∏ô 0

# ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ Batch Normalization ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏π‡∏ï‡∏£
normalized = (batch - mean) / (std + epsilon)
output = gamma * normalized + beta

# ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ Haversine Formula ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
distance = 2R √ó arcsin(‚àöa)
where a = sin¬≤(Œîlat/2) + cos(lat1)√ócos(lat2)√ósin¬≤(Œîlon/2)
```

---

### **3. üìä DATA_PROCESSING_TH.md - ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏´‡∏ô‡∏≤ 400+ ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î)**

**Path:** `docs/DATA_PROCESSING_TH.md`

**‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤:**
- ‚úÖ **‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ**:
  - PROBE Data - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• GPS
  - OpenStreetMap - ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ñ‡∏ô‡∏ô
  - Traffic Events - ‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå
- ‚úÖ **‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**:
  - ‡∏•‡∏ö outliers - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
  - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ missing data - interpolation, fill
  - Quality filtering - ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
- ‚úÖ **Feature Engineering**:
  - Speed features - mean, median, std (‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì)
  - Temporal features - sine/cosine encoding (‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ)
  - Count features - ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô probes
  - Labels - congestion, rush hour
- ‚úÖ **‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á**:
  - **Haversine Formula** - ‡∏™‡∏π‡∏ï‡∏£‡πÄ‡∏ï‡πá‡∏° ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô
  - Distance matrix - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏π‡πà
- ‚úÖ **‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**:
  - Train/Val/Test split - 70/15/15
  - Stratified split - ‡πÄ‡∏Å‡πá‡∏ö‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô labels
- ‚úÖ **Data Augmentation**:
  - Noise injection - ‡πÄ‡∏û‡∏¥‡πà‡∏° robustness
  - Feature scaling - Standardization

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
```python
# ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ Haversine Formula ‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô
# Step 1: ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô radians
lat1_rad = 13.7447 * œÄ/180 = 0.2399
lon1_rad = 100.5298 * œÄ/180 = 1.7544

# Step 2: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á
dlat = lat2_rad - lat1_rad = 0.0001
dlon = lon2_rad - lon1_rad = 0.0008

# Step 3: Haversine formula
a = sin¬≤(dlat/2) + cos(lat1_rad) √ó cos(lat2_rad) √ó sin¬≤(dlon/2)
  = 0.0000001533

# Step 4: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì c
c = 2 √ó arcsin(‚àöa) = 0.000784

# Step 5: ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á
distance = 6371 √ó 0.000784 = 4.99 km

# ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ Sine/Cosine Encoding
# ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ:
hour = 23  # 23:00
hour = 0   # 00:00
# ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ ‚Üí ‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 23 (‡∏ú‡∏¥‡∏î!)

# ‡πÉ‡∏ä‡πâ sine/cosine:
hour_sin = sin(2œÄ √ó hour / 24)
hour_cos = cos(2œÄ √ó hour / 24)
# 23:00 ‡πÅ‡∏•‡∏∞ 00:00 ‡∏à‡∏∞‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô‡πÉ‡∏ô sine/cosine space (‡∏ñ‡∏π‡∏Å!)
```

---

### **4. üìö GUIDE_INDEX_TH.md - ‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ (‡∏´‡∏ô‡∏≤ 300+ ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î)**

**Path:** `docs/GUIDE_INDEX_TH.md`

**‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤:**
- ‚úÖ ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
- ‚úÖ ‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:
  - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
  - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏°‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
  - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Research/Production
- ‚úÖ ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á
- ‚úÖ Tips ‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£

---

## üéØ ‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£

### **1. ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢**
```
‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: "use GNN for spatio-temporal analysis"
‚úÖ ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤: "‡πÉ‡∏ä‡πâ Graph Neural Network (‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡πÄ‡∏ó‡∏µ‡∏¢‡∏°
    ‡πÅ‡∏ö‡∏ö‡∏Å‡∏£‡∏≤‡∏ü) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏°‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤"
```

### **2. ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ**
```
Epoch = ‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô = ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î 1 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á
Batch = ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• = ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏•‡∏∞‡∏Å‡∏µ‡πà‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
Loss = ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î = ‡∏ß‡∏±‡∏î‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏¥‡∏î‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô
Gradient = ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏ô = ‡∏ö‡∏≠‡∏Å‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö weight
```

### **3. ‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô**

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Haversine:**
```python
# ‡∏à‡∏∏‡∏î A: MBK Center
lat1 = 13.7447, lon1 = 100.5298

# ‡∏à‡∏∏‡∏î B: Siam Paragon
lat2 = 13.7467, lon2 = 100.5343

# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô (‡∏°‡∏µ 5 steps)
‚Üí ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á = 0.523 km
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Standard Deviation:**
```python
speeds = [40, 42, 45, 48, 50, 38, 41]

mean = (40+42+45+48+50+38+41) / 7 = 43.43
std = sqrt(Œ£(x - mean)¬≤ / n) = 2.87 km/h
```

### **4. ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ô‡∏±‡πâ‡∏ô**
```python
# ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Batch Normalization?
‚Üí ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£
‚Üí ‡πÄ‡∏£‡πà‡∏á‡∏Å‡∏≤‡∏£ convergence
‚Üí ‡∏•‡∏î internal covariate shift

# ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Residual Connections?
‚Üí ‡πÅ‡∏Å‡πâ vanishing gradient problem
‚Üí ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡∏£‡∏ô deep network ‡πÑ‡∏î‡πâ
‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á"

# ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Sine/Cosine Encoding?
‚Üí ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏ô‡∏ã‡πâ‡∏≥ (cyclic)
‚Üí 23:00 ‡πÅ‡∏•‡∏∞ 00:00 ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô
‚Üí ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤: ‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 23 (‡∏ú‡∏¥‡∏î!)
‚Üí Sine/cosine: ‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô (‡∏ñ‡∏π‡∏Å!)
```

### **5. ‡∏°‡∏µ‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏û‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö (ASCII art)**
```
# ReLU Activation
     ‚îÇ
   2 ‚îÇ         ‚ï±
   1 ‚îÇ       ‚ï±
   0 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ x
  -1 ‚îÇ
  -2 ‚îÇ

# Simple Model Architecture
Input (10 features)
    ‚Üì
[Linear Layer 1] ‚Üí 64 neurons
    ‚Üì
[ReLU Activation]
    ‚Üì
[Linear Layer 2] ‚Üí 64 neurons
    ‚Üì
[ReLU Activation]
    ‚Üì
    ‚îú‚îÄ‚îÄ‚Üí [Congestion Head] ‚Üí 4 outputs
    ‚îî‚îÄ‚îÄ‚Üí [Rush Hour Head] ‚Üí 2 outputs
```

---

## üìñ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£

### **‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô:**
```
1. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏µ‡πà docs/README_TH.md
   - ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°
   - ‡∏î‡∏π‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ
   - ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô

2. ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
   - ‡∏£‡∏±‡∏ô Simple Training
   - ‡πÄ‡∏õ‡∏¥‡∏î Dashboard

3. ‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
   - docs/DATA_PROCESSING_TH.md (‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
   - docs/TECHNICAL_DETAILS_TH.md (‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÇ‡∏°‡πÄ‡∏î‡∏•)
```

### **‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:**
```
1. docs/TECHNICAL_DETAILS_TH.md (‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏•‡∏∂‡∏Å)
2. ‡∏£‡∏±‡∏ô Enhanced Training
3. ‡∏≠‡πà‡∏≤‡∏ô TRAINING_IMPROVEMENTS.md
4. ‡∏ó‡∏î‡∏•‡∏≠‡∏á Hyperparameter Search
```

---

## üéì ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ

‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à:

### **1. Machine Learning Basics**
- Training, Validation, Testing ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£
- Overfitting, Underfitting ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£
- Epoch, Batch, Loss, Accuracy

### **2. Neural Networks**
- Neuron, Layer, Weight, Bias
- Activation Functions (ReLU, Softmax)
- Forward Pass, Backward Pass
- Gradient Descent

### **3. Graph Neural Networks**
- Graph, Node, Edge ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£
- Message Passing
- Aggregation
- ‡∏ó‡∏≥‡πÑ‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£

### **4. Advanced Techniques**
- Batch Normalization
- Residual Connections
- Attention Mechanism
- Dropout

### **5. Optimization**
- AdamW Optimizer
- Learning Rate Scheduling
- Gradient Clipping
- Early Stopping

### **6. Data Processing**
- Data Cleaning
- Feature Engineering
- Haversine Formula
- Temporal Encoding
- Data Augmentation

### **7. ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡πà‡∏≤‡∏á‡πÜ**
- Matrix Multiplication
- Haversine Distance
- Standard Deviation
- Sine/Cosine Encoding
- Softmax
- Cross-Entropy Loss

---

## üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£

```
‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: 4 ‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å
‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î: ~1,500+ ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢: ~150+ ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠
‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î: ~100+ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
‡∏™‡∏π‡∏ï‡∏£‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì: ~50+ ‡∏™‡∏π‡∏ï‡∏£
‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì: ~30+ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
```

---

## üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà!

### **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏≠‡πà‡∏≤‡∏ô‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô**
üìñ [`docs/README_TH.md`](./docs/README_TH.md)

### **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏î‡∏π‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£**
üìö [`docs/GUIDE_INDEX_TH.md`](./docs/GUIDE_INDEX_TH.md)

### **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à**
- ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‚Üí [`docs/DATA_PROCESSING_TH.md`](./docs/DATA_PROCESSING_TH.md)
- ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÇ‡∏°‡πÄ‡∏î‡∏• ‚Üí [`docs/TECHNICAL_DETAILS_TH.md`](./docs/TECHNICAL_DETAILS_TH.md)

---

## ‚úÖ ‡∏™‡∏£‡∏∏‡∏õ

‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà:

‚úÖ **‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á** - ‡∏à‡∏≤‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ñ‡∏∂‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á  
‚úÖ **‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢** - ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏®‡∏±‡∏û‡∏ó‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢  
‚úÖ **‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏¢‡∏≠‡∏∞** - ‡πÇ‡∏Ñ‡πâ‡∏î, ‡∏™‡∏π‡∏ï‡∏£, ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì  
‚úÖ **‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡πÑ‡∏°** - ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏Ñ‡πà "‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£"  
‚úÖ **‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å‡∏™‡πà‡∏ß‡∏ô** - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•, ‡πÇ‡∏°‡πÄ‡∏î‡∏•, ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô  

**‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏π‡πâ ‡∏°‡∏µ‡∏Ñ‡∏£‡∏ö‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ!**

**‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏•‡∏¢:** [`docs/README_TH.md`](./docs/README_TH.md)

**‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏ô‡∏∏‡∏Å‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ! üéìüöÄ**
