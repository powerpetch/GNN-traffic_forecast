# üìò ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÇ‡∏Ñ‡πâ‡∏î: data_processor.py

## üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ü‡∏•‡πå

- **‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå:** `src/data/data_processor.py`
- **‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:** ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
- **‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î:** ~530 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
- **‡∏†‡∏≤‡∏©‡∏≤:** Python
- **‡∏Ñ‡∏•‡∏≤‡∏™‡∏´‡∏•‡∏±‡∏Å:** `TrafficDataProcessor`

---

## üéØ ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°

‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô **Data Processing Pipeline** ‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö (GPS probes) ‡πÉ‡∏´‡πâ‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏• GNN ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ

### **Pipeline ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•:**

```
1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PROBE
   ‚Üì
2. Map-matching ‡∏Å‡∏±‡∏ö‡∏ñ‡∏ô‡∏ô (OSM)
   ‚Üì
3. Aggregate ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (5 ‡∏ô‡∏≤‡∏ó‡∏µ)
   ‚Üì
4. ‡∏™‡∏£‡πâ‡∏≤‡∏á Features (10 features)
   ‚Üì
5. ‡∏™‡∏£‡πâ‡∏≤‡∏á Labels (4+2 classes)
   ‚Üì
6. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ
```

---

## üìÇ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏•‡∏≤‡∏™ TrafficDataProcessor

```python
class TrafficDataProcessor:
    """‡∏Ñ‡∏•‡∏≤‡∏™‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£"""
    
    # Constructor
    __init__()
    
    # 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    load_probe_data()
    load_road_network()
    
    # 2. Map-matching
    map_match_to_network()
    build_spatial_index()
    find_nearest_road()
    
    # 3. Aggregate ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    aggregate_by_time()
    aggregate_by_location()
    
    # 4. Feature Engineering
    create_temporal_features()
    create_spatial_features()
    create_lag_features()
    create_statistical_features()
    
    # 5. Label Creation
    create_congestion_labels()
    create_rush_hour_labels()
    
    # 6. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å/‡πÇ‡∏´‡∏•‡∏î
    save_processed_data()
    load_processed_data()
    
    # 7. Utilities
    haversine_distance()
    validate_data()
    get_statistics()
```

---

## 1Ô∏è‚É£ Constructor - ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô

```python
def __init__(self, data_path: str = "..."):
    """
    ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™ TrafficDataProcessor
    
    Parameters:
        data_path (str): path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö
    
    Attributes:
        self.road_network: ‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏ñ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å OSM
        self.spatial_index: R-tree index ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏£‡πá‡∏ß
        self.processed_data: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß
        self.speed_thresholds: ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡πÅ‡∏ö‡πà‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£
        self.rush_hours: ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô
    """
    
    self.data_path = data_path
    self.road_network = None
    self.spatial_index = None
    self.processed_data = None
    
    # ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£
    self.speed_thresholds = {
        'gridlock': 10,      # < 10 km/h
        'congested': 25,     # 10-25 km/h
        'moderate': 40,      # 25-40 km/h
        'free_flow': 999     # > 40 km/h
    }
    
    # ‡∏ä‡πà‡∏ß‡∏á‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô
    self.rush_hours = [
        (7, 9),    # ‡πÄ‡∏ä‡πâ‡∏≤ 7:00-9:00
        (17, 19)   # ‡πÄ‡∏¢‡πá‡∏ô 17:00-19:00
    ]
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ:**
```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á processor
processor = TrafficDataProcessor(
    data_path="Data/PROBE-202401"
)

print(processor.speed_thresholds)
# {'gridlock': 10, 'congested': 25, ...}
```

---

## 2Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

### **üì• load_probe_data() - ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• GPS**

```python
def load_probe_data(self, date_pattern: str = "2024*") -> pd.DataFrame:
    """
    ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PROBE ‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå
    
    Parameters:
        date_pattern: pattern ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå (‡πÄ‡∏ä‡πà‡∏ô "2024*" = ‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏µ 2024)
    
    Returns:
        DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå:
        - timestamp: ‡∏ß‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤
        - latitude: ‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î
        - longitude: ‡∏•‡∏≠‡∏á‡∏à‡∏¥‡∏à‡∏π‡∏î
        - speed: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß (km/h)
        - heading: ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á (0-360¬∞)
        - quality: ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û (0-1)
    
    ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô:
        1. ‡∏´‡∏≤‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö pattern
        2. ‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå
        3. ‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        4. ‡πÅ‡∏õ‡∏•‡∏á timestamp ‡πÄ‡∏õ‡πá‡∏ô datetime
        5. ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
    """
    
    import glob
    
    # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    files = glob.glob(f"{self.data_path}/{date_pattern}.csv")
    print(f"Found {len(files)} files")
    
    # ‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå
    dfs = []
    for file in files:
        df = pd.read_csv(file)
        dfs.append(df)
    
    # ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå
    combined = pd.concat(dfs, ignore_index=True)
    
    # ‡πÅ‡∏õ‡∏•‡∏á timestamp
    combined['timestamp'] = pd.to_datetime(combined['timestamp'])
    
    # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    combined = combined[
        (combined['speed'] >= 0) &
        (combined['speed'] <= 150) &
        (combined['quality'] >= 0.3)
    ]
    
    return combined
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:**
```python
# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
df = processor.load_probe_data("202401*")

print(df.head())
```

| timestamp | latitude | longitude | speed | heading | quality |
|-----------|----------|-----------|-------|---------|---------|
| 2024-01-01 00:05:00 | 13.7563 | 100.5018 | 45.5 | 90.0 | 0.85 |
| 2024-01-01 00:05:15 | 13.7565 | 100.5020 | 46.2 | 92.5 | 0.88 |
| 2024-01-01 00:05:30 | 13.7567 | 100.5022 | 44.8 | 89.0 | 0.82 |

---

### **üó∫Ô∏è load_road_network() - ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏ô‡∏ô**

```python
def load_road_network(self, road_path: str) -> gpd.GeoDataFrame:
    """
    ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏ñ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å HOTOSM (OpenStreetMap)
    
    Parameters:
        road_path: path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå .gpkg (GeoPackage)
    
    Returns:
        GeoDataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ:
        - geometry: ‡πÄ‡∏™‡πâ‡∏ô‡∏ñ‡∏ô‡∏ô (LineString)
        - highway: ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ñ‡∏ô‡∏ô (primary, secondary, ...)
        - name: ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏ô‡∏ô (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
        - maxspeed: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    
    ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô:
        1. ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå GeoPackage
        2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ñ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Spatial Index (R-tree)
    """
    
    # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå
    roads = gpd.read_file(road_path)
    
    # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ñ‡∏ô‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
    important_roads = [
        'motorway', 'trunk', 'primary', 
        'secondary', 'tertiary'
    ]
    roads = roads[roads['highway'].isin(important_roads)]
    
    # ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ
    self.road_network = roads
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á spatial index
    self.build_spatial_index()
    
    return roads
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
# ‡πÇ‡∏´‡∏•‡∏î‡∏ñ‡∏ô‡∏ô
roads = processor.load_road_network(
    "Data/hotosm_tha_roads_lines_gpkg/roads.gpkg"
)

print(f"Loaded {len(roads)} roads")
print(roads[['highway', 'name']].head())
```

| highway | name |
|---------|------|
| primary | ‡∏ñ‡∏ô‡∏ô‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏° 1 |
| motorway | ‡∏ó‡∏≤‡∏á‡∏î‡πà‡∏ß‡∏ô‡∏®‡∏£‡∏µ‡∏£‡∏±‡∏ä |
| secondary | ‡∏ñ‡∏ô‡∏ô‡∏™‡∏∏‡∏Ç‡∏∏‡∏°‡∏ß‡∏¥‡∏ó |

---

## 3Ô∏è‚É£ Map-Matching - ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏ñ‡∏ô‡∏ô

### **üéØ map_match_to_network() - ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà GPS ‡∏Å‡∏±‡∏ö‡∏ñ‡∏ô‡∏ô**

```python
def map_match_to_network(self, df: pd.DataFrame, 
                         max_distance: float = 100) -> pd.DataFrame:
    """
    ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏à‡∏∏‡∏î GPS ‡∏Å‡∏±‡∏ö‡∏ñ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    
    Parameters:
        df: DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏û‡∏¥‡∏Å‡∏±‡∏î GPS
        max_distance: ‡∏£‡∏∞‡∏¢‡∏∞‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ (‡πÄ‡∏°‡∏ï‡∏£)
    
    Returns:
        DataFrame + ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°:
        - road_id: ID ‡∏Ç‡∏≠‡∏á‡∏ñ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà
        - distance_to_road: ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏ñ‡∏ô‡∏ô (‡πÄ‡∏°‡∏ï‡∏£)
        - matched_point: ‡∏à‡∏∏‡∏î‡∏ö‡∏ô‡∏ñ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    
    ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô:
        1. ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏à‡∏∏‡∏î GPS
        2. ‡∏´‡∏≤‡∏ñ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡πÉ‡∏ä‡πâ R-tree)
        3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á
        4. ‡∏ñ‡πâ‡∏≤ distance <= max_distance ‚Üí ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà
        5. ‡∏ñ‡πâ‡∏≤ distance > max_distance ‚Üí ‡∏ó‡∏¥‡πâ‡∏á
    """
    
    matched_data = []
    
    for idx, row in df.iterrows():
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏∏‡∏î GPS
        point = Point(row['longitude'], row['latitude'])
        
        # ‡∏´‡∏≤‡∏ñ‡∏ô‡∏ô‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        road_id, distance = self.find_nearest_road(point)
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á
        if distance <= max_distance:
            row['road_id'] = road_id
            row['distance_to_road'] = distance
            matched_data.append(row)
    
    return pd.DataFrame(matched_data)
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
# ‡∏Å‡πà‡∏≠‡∏ô map-matching
print(df[['latitude', 'longitude', 'speed']].head())
```

| latitude | longitude | speed |
|----------|-----------|-------|
| 13.7563 | 100.5018 | 45.5 |
| 13.7565 | 100.5020 | 46.2 |

```python
# ‡∏´‡∏•‡∏±‡∏á map-matching
matched = processor.map_match_to_network(df, max_distance=50)
print(matched[['latitude', 'longitude', 'speed', 'road_id', 'distance_to_road']].head())
```

| latitude | longitude | speed | road_id | distance_to_road |
|----------|-----------|-------|---------|------------------|
| 13.7563 | 100.5018 | 45.5 | ROAD_123 | 15.3 |
| 13.7565 | 100.5020 | 46.2 | ROAD_123 | 12.8 |

---

### **üîç find_nearest_road() - ‡∏´‡∏≤‡∏ñ‡∏ô‡∏ô‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î**

```python
def find_nearest_road(self, point: Point) -> Tuple[str, float]:
    """
    ‡∏´‡∏≤‡∏ñ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ö‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    
    Parameters:
        point: ‡∏à‡∏∏‡∏î GPS (Point object)
    
    Returns:
        (road_id, distance): ID ‡∏ñ‡∏ô‡∏ô ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á (‡πÄ‡∏°‡∏ï‡∏£)
    
    Algorithm:
        1. ‡πÉ‡∏ä‡πâ R-tree spatial index ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ñ‡∏ô‡∏ô‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á
        2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡πÅ‡∏ö‡∏ö Haversine
        3. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ñ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏¢‡∏∞‡∏™‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    """
    
    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ñ‡∏ô‡∏ô‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢ R-tree
    candidates = self.spatial_index.nearest(
        (point.x, point.y, point.x, point.y), 
        5  # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ 5 ‡∏ñ‡∏ô‡∏ô‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    )
    
    min_distance = float('inf')
    nearest_road = None
    
    # ‡∏´‡∏≤‡∏ñ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    for road_idx in candidates:
        road_geom = self.road_network.iloc[road_idx].geometry
        distance = point.distance(road_geom)
        
        if distance < min_distance:
            min_distance = distance
            nearest_road = self.road_network.iloc[road_idx]['road_id']
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏°‡∏ï‡∏£
    distance_meters = min_distance * 111000  # degrees ‚Üí meters
    
    return nearest_road, distance_meters
```

**‡∏†‡∏≤‡∏û‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö:**
```
      GPS Point (‚óè)
         |
         | 15 m (distance_to_road)
         |
    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê  Road (ROAD_123)
```

---

## 4Ô∏è‚É£ Aggregation - ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

### **‚è∞ aggregate_by_time() - ‡∏£‡∏ß‡∏°‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤**

```python
def aggregate_by_time(self, df: pd.DataFrame, 
                      bin_minutes: int = 5) -> pd.DataFrame:
    """
    ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏∏‡∏Å‡πÜ N ‡∏ô‡∏≤‡∏ó‡∏µ
    
    Parameters:
        df: DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ timestamp ‡πÅ‡∏•‡∏∞ speed
        bin_minutes: ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏° (‡∏ô‡∏≤‡∏ó‡∏µ)
    
    Returns:
        DataFrame ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡πÅ‡∏•‡πâ‡∏ß ‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå:
        - time_bin: ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤ (‡πÄ‡∏ä‡πà‡∏ô "08:00-08:05")
        - road_id: ID ‡∏ñ‡∏ô‡∏ô
        - count: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        - mean_speed: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
        - median_speed: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏•‡∏≤‡∏á
        - std_speed: ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏ö‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ö‡∏ô
        - min_speed: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î
        - max_speed: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    
    ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô:
        1. ‡∏™‡∏£‡πâ‡∏≤‡∏á time bins (‡∏ó‡∏∏‡∏Å 5 ‡∏ô‡∏≤‡∏ó‡∏µ)
        2. ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏° (time_bin, road_id)
        3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Å‡∏•‡∏∏‡πà‡∏°
    """
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á time bins
    df['time_bin'] = df['timestamp'].dt.floor(f'{bin_minutes}min')
    
    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
    aggregated = df.groupby(['time_bin', 'road_id']).agg({
        'speed': ['count', 'mean', 'median', 'std', 'min', 'max'],
        'quality': 'mean'
    }).reset_index()
    
    # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
    aggregated.columns = [
        'time_bin', 'road_id', 'count', 
        'mean_speed', 'median_speed', 'std_speed',
        'min_speed', 'max_speed', 'mean_quality'
    ]
    
    # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠
    aggregated = aggregated[aggregated['count'] >= 3]
    
    return aggregated
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**

**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö (‡∏ó‡∏∏‡∏Å‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ):**
```python
timestamp            road_id  speed
08:00:00            ROAD_1   45
08:00:30            ROAD_1   47
08:01:15            ROAD_1   43
08:02:00            ROAD_1   46
08:03:30            ROAD_1   44
```

**‡∏´‡∏•‡∏±‡∏á Aggregate (‡∏ó‡∏∏‡∏Å 5 ‡∏ô‡∏≤‡∏ó‡∏µ):**
```python
time_bin         road_id  count  mean_speed  median_speed  std_speed
08:00-08:05     ROAD_1   5      45.0        45.0          1.58
```

---

### **üìç aggregate_by_location() - ‡∏£‡∏ß‡∏°‡∏ï‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà**

```python
def aggregate_by_location(self, df: pd.DataFrame) -> pd.DataFrame:
    """
    ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á
    
    Parameters:
        df: DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏û‡∏¥‡∏Å‡∏±‡∏î
    
    Returns:
        DataFrame ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏ï‡∏≤‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß
    
    ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô:
        1. ‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡πÄ‡∏õ‡πá‡∏ô grid (‡πÄ‡∏ä‡πà‡∏ô 0.01¬∞ √ó 0.01¬∞)
        2. ‡∏à‡∏±‡∏î‡∏à‡∏∏‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏à‡∏∏‡∏î‡πÄ‡∏Ç‡πâ‡∏≤ grid
        3. ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô grid ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
    """
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á grid
    df['grid_lat'] = (df['latitude'] / 0.01).round() * 0.01
    df['grid_lon'] = (df['longitude'] / 0.01).round() * 0.01
    df['location_id'] = df['grid_lat'].astype(str) + '_' + df['grid_lon'].astype(str)
    
    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°
    aggregated = df.groupby(['time_bin', 'location_id']).agg({
        'speed': ['mean', 'std'],
        'count': 'sum'
    })
    
    return aggregated
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```
Grid: 0.01¬∞ √ó 0.01¬∞ (‚âà 1.1 km √ó 1.1 km)

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ (13.75, ‚îÇ (13.75, ‚îÇ (13.75, ‚îÇ
‚îÇ 100.50) ‚îÇ 100.51) ‚îÇ 100.52) ‚îÇ
‚îÇ 10 pts  ‚îÇ 15 pts  ‚îÇ 8 pts   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ (13.74, ‚îÇ (13.74, ‚îÇ (13.74, ‚îÇ
‚îÇ 100.50) ‚îÇ 100.51) ‚îÇ 100.52) ‚îÇ
‚îÇ 12 pts  ‚îÇ 20 pts  ‚îÇ 5 pts   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 5Ô∏è‚É£ Feature Engineering - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥

### **‚è∞ create_temporal_features() - Features ‡πÄ‡∏ß‡∏•‡∏≤**

```python
def create_temporal_features(self, df: pd.DataFrame) -> pd.DataFrame:
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤
    
    Features ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á:
        1. hour_sin: sine encoding ‡∏Ç‡∏≠‡∏á‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
        2. hour_cos: cosine encoding ‡∏Ç‡∏≠‡∏á‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
        3. day_of_week: ‡∏ß‡∏±‡∏ô‡πÉ‡∏ô‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå (0-6)
        4. is_weekend: ‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (0/1)
        5. is_holiday: ‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î‡∏ô‡∏±‡∏Å‡∏Ç‡∏±‡∏ï‡∏§‡∏Å‡∏©‡πå (0/1)
        6. time_since_rush_hour: ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô (‡∏ä‡∏°.)
    
    Cyclical Encoding:
        ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á encode ‡πÄ‡∏õ‡πá‡∏ô sin/cos?
        - ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏á‡∏Å‡∏•‡∏°: 23:00 ‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ö 00:00
        - ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ 0-23 ‡∏ï‡∏£‡∏á‡πÜ ‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤ 23 ‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å 0 ‡∏°‡∏≤‡∏Å
        - ‡πÉ‡∏ä‡πâ sin/cos ‚Üí ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏á‡∏Å‡∏•‡∏°
    """
    
    # ‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡∏•‡∏≤
    df['hour'] = df['timestamp'].dt.hour
    df['day_of_week'] = df['timestamp'].dt.dayofweek
    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)
    
    # Cyclical encoding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
    
    # ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô
    df['time_since_rush_hour'] = df.apply(
        lambda row: self._calculate_time_since_rush(row['hour']), 
        axis=1
    )
    
    return df
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Cyclical Encoding:**

| hour | hour_sin | hour_cos | ‡∏†‡∏≤‡∏û‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö |
|------|----------|----------|-----------|
| 0 | 0.000 | 1.000 | 12 o'clock (‡∏ö‡∏ô) |
| 6 | 1.000 | 0.000 | 3 o'clock (‡∏Ç‡∏ß‡∏≤) |
| 12 | 0.000 | -1.000 | 6 o'clock (‡∏•‡πà‡∏≤‡∏á) |
| 18 | -1.000 | 0.000 | 9 o'clock (‡∏ã‡πâ‡∏≤‡∏¢) |
| 23 | -0.259 | 0.966 | ‡πÉ‡∏Å‡∏•‡πâ 12 |

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì:**
```python
hour = 14  # 14:00
angle = 2 * œÄ * 14 / 24 = 3.665 radians

hour_sin = sin(3.665) = -0.259
hour_cos = cos(3.665) = -0.966
```

---

### **üìä create_statistical_features() - Features ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥**

```python
def create_statistical_features(self, df: pd.DataFrame) -> pd.DataFrame:
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡∏ó‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
    
    Features:
        1. speed_mean: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
        2. speed_median: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏•‡∏≤‡∏á
        3. speed_std: ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏ö‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ö‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
        4. speed_percentile_25: Percentile 25
        5. speed_percentile_75: Percentile 75
        6. speed_range: ‡∏ä‡πà‡∏ß‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß (max - min)
        7. speed_cv: Coefficient of Variation (std/mean)
    """
    
    # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
    df['speed_mean'] = df['speed'].mean()
    df['speed_median'] = df['speed'].median()
    df['speed_std'] = df['speed'].std()
    
    # Percentiles
    df['speed_p25'] = df['speed'].quantile(0.25)
    df['speed_p75'] = df['speed'].quantile(0.75)
    
    # ‡∏Ñ‡πà‡∏≤‡∏≠‡∏∑‡πà‡∏ô‡πÜ
    df['speed_range'] = df['speed'].max() - df['speed'].min()
    df['speed_cv'] = df['speed_std'] / (df['speed_mean'] + 1e-6)
    
    return df
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß 5 ‡∏ô‡∏≤‡∏ó‡∏µ
speeds = [42, 45, 43, 46, 44, 47, 41, 45, 43, 46]

# Features ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ
speed_mean = 44.2 km/h
speed_median = 44.5 km/h
speed_std = 1.93 km/h
speed_p25 = 43.0 km/h
speed_p75 = 46.0 km/h
speed_range = 6.0 km/h (47-41)
speed_cv = 0.044 (1.93/44.2)
```

**Coefficient of Variation (CV) ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢:**
- CV = std / mean
- CV ‡∏ï‡πà‡∏≥ (< 0.2) = ‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£ (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Ñ‡∏á‡∏ó‡∏µ‡πà)
- CV ‡∏™‡∏π‡∏á (> 0.5) = ‡∏ú‡∏±‡∏ô‡πÅ‡∏õ‡∏£ (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î)

```python
# ‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£
speeds = [44, 45, 44, 45, 44]
CV = 0.5 / 44.4 = 0.011  (‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏°‡∏≤‡∏Å)

# ‡∏ú‡∏±‡∏ô‡πÅ‡∏õ‡∏£
speeds = [20, 60, 15, 70, 10]
CV = 25.5 / 35 = 0.729  (‡∏ú‡∏±‡∏ô‡πÅ‡∏õ‡∏£‡∏°‡∏≤‡∏Å)
```

---

### **üîÑ create_lag_features() - Features ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á**

```python
def create_lag_features(self, df: pd.DataFrame, 
                       lags: List[int] = [1, 2, 3]) -> pd.DataFrame:
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á lag features (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡πà‡∏ß‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤)
    
    Parameters:
        lags: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô time steps ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á
              [1, 2, 3] = ‡∏¢‡πâ‡∏≠‡∏ô 5, 10, 15 ‡∏ô‡∏≤‡∏ó‡∏µ
    
    Features:
        - speed_lag_1: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß 5 ‡∏ô‡∏≤‡∏ó‡∏µ‡∏Å‡πà‡∏≠‡∏ô
        - speed_lag_2: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß 10 ‡∏ô‡∏≤‡∏ó‡∏µ‡∏Å‡πà‡∏≠‡∏ô
        - speed_lag_3: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß 15 ‡∏ô‡∏≤‡∏ó‡∏µ‡∏Å‡πà‡∏≠‡∏ô
        - speed_diff_1: ‡∏ú‡∏•‡∏ï‡πà‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß (current - lag_1)
        - speed_trend: ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏° (‡πÄ‡∏û‡∏¥‡πà‡∏°/‡∏•‡∏î)
    """
    
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤
    df = df.sort_values(['road_id', 'time_bin'])
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á lag features
    for lag in lags:
        df[f'speed_lag_{lag}'] = df.groupby('road_id')['speed'].shift(lag)
        df[f'speed_diff_{lag}'] = df['speed'] - df[f'speed_lag_{lag}']
    
    # ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°
    df['speed_trend'] = np.sign(df['speed_diff_1'])
    
    # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ
    df = df.fillna(method='bfill')
    
    return df
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**

| time_bin | speed | speed_lag_1 | speed_lag_2 | speed_diff_1 | speed_trend |
|----------|-------|-------------|-------------|--------------|-------------|
| 08:00 | 45 | NaN | NaN | NaN | 0 |
| 08:05 | 48 | 45 | NaN | +3 | +1 |
| 08:10 | 43 | 48 | 45 | -5 | -1 |
| 08:15 | 47 | 43 | 48 | +4 | +1 |

**‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏Ç‡∏≠‡∏á Lag Features:**
- ‡πÇ‡∏°‡πÄ‡∏î‡∏• "‡∏£‡∏π‡πâ" ‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
- ‡∏à‡∏±‡∏ö‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏° (‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏¥‡∏î‡∏Ç‡∏±‡∏î/‡∏Ñ‡∏•‡πà‡∏≠‡∏á‡∏ï‡∏±‡∏ß)
- ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô

---

### **üåê create_spatial_features() - Features ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà**

```python
def create_spatial_features(self, df: pd.DataFrame) -> pd.DataFrame:
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà
    
    Features:
        1. nearby_avg_speed: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á
        2. nearby_congestion: ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á
        3. distance_to_center: ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡πÉ‡∏à‡∏Å‡∏•‡∏≤‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á
        4. road_density: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡∏≤‡πÅ‡∏ô‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡∏ñ‡∏ô‡∏ô
        5. is_main_road: ‡∏ñ‡∏ô‡∏ô‡∏™‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    """
    
    # ‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á (‡∏†‡∏≤‡∏¢‡πÉ‡∏ô 500 ‡πÄ‡∏°‡∏ï‡∏£)
    df['nearby_avg_speed'] = df.apply(
        lambda row: self._get_nearby_speed(
            row['latitude'], 
            row['longitude'], 
            radius=500
        ),
        axis=1
    )
    
    # ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡πÉ‡∏à‡∏Å‡∏•‡∏≤‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á (‡∏™‡∏¢‡∏≤‡∏°)
    center = (13.7465, 100.5326)  # Siam Square
    df['distance_to_center'] = df.apply(
        lambda row: self.haversine_distance(
            row['latitude'], row['longitude'],
            center[0], center[1]
        ),
        axis=1
    )
    
    # ‡∏ñ‡∏ô‡∏ô‡∏™‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏Å
    main_roads = ['motorway', 'trunk', 'primary']
    df['is_main_road'] = df['highway'].isin(main_roads).astype(int)
    
    return df
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**

| location | speed | nearby_avg_speed | distance_to_center | is_main_road |
|----------|-------|------------------|--------------------|--------------|
| Siam | 45 | 43.5 | 0 km | 1 |
| MBK | 42 | 43.5 | 0.5 km | 1 |
| Silom | 38 | 35.2 | 2.3 km | 1 |
| Sukhumvit | 50 | 48.7 | 3.5 km | 1 |

---

## 6Ô∏è‚É£ Label Creation - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≥‡∏Å‡∏±‡∏ö

### **üö¶ create_congestion_labels() - ‡∏õ‡πâ‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£**

```python
def create_congestion_labels(self, df: pd.DataFrame) -> pd.DataFrame:
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á labels ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£ (4 classes)
    
    Classes:
        0: Gridlock    (< 10 km/h)    ‡∏ï‡∏¥‡∏î‡∏Ç‡∏±‡∏î‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á
        1: Congested   (10-25 km/h)   ‡∏ï‡∏¥‡∏î‡∏Ç‡∏±‡∏î
        2: Moderate    (25-40 km/h)   ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á
        3: Free Flow   (> 40 km/h)    ‡∏Ñ‡∏•‡πà‡∏≠‡∏á‡∏ï‡∏±‡∏ß
    
    Returns:
        DataFrame + ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå:
        - congestion_label: class (0-3)
        - congestion_name: ‡∏ä‡∏∑‡πà‡∏≠ class
    """
    
    def classify_speed(speed):
        if speed < 10:
            return 0, "Gridlock"
        elif speed < 25:
            return 1, "Congested"
        elif speed < 40:
            return 2, "Moderate"
        else:
            return 3, "Free Flow"
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á labels
    df[['congestion_label', 'congestion_name']] = df['mean_speed'].apply(
        lambda x: pd.Series(classify_speed(x))
    )
    
    return df
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**

| time_bin | mean_speed | congestion_label | congestion_name |
|----------|------------|------------------|-----------------|
| 08:00 | 8 | 0 | Gridlock |
| 08:05 | 18 | 1 | Congested |
| 08:10 | 32 | 2 | Moderate |
| 08:15 | 55 | 3 | Free Flow |

**‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á Classes:**
```python
# ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ class
print(df['congestion_label'].value_counts())

# Output:
# 3 (Free Flow)    45,230  (45%)
# 2 (Moderate)     28,150  (28%)
# 1 (Congested)    18,420  (18%)
# 0 (Gridlock)      8,200  (8%)
```

---

### **‚è∞ create_rush_hour_labels() - ‡∏õ‡πâ‡∏≤‡∏¢‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô**

```python
def create_rush_hour_labels(self, df: pd.DataFrame) -> pd.DataFrame:
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á labels ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô (2 classes)
    
    Classes:
        0: Non-Rush Hour   ‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥
        1: Rush Hour       ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô (7-9, 17-19 ‡∏ô.)
    
    ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç:
        - ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ (‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå-‡∏®‡∏∏‡∏Å‡∏£‡πå)
        - ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤ 7-9 ‡∏´‡∏£‡∏∑‡∏≠ 17-19 ‡∏ô.
    """
    
    def is_rush_hour(row):
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î
        if row['is_weekend'] == 1:
            return 0, "Non-Rush Hour"
        
        hour = row['hour']
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤
        for start, end in self.rush_hours:
            if start <= hour < end:
                return 1, "Rush Hour"
        
        return 0, "Non-Rush Hour"
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á labels
    df[['rush_hour_label', 'rush_hour_name']] = df.apply(
        lambda row: pd.Series(is_rush_hour(row)),
        axis=1
    )
    
    return df
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**

| timestamp | hour | is_weekend | rush_hour_label | rush_hour_name |
|-----------|------|------------|-----------------|----------------|
| 2024-01-15 08:00 | 8 | 0 | 1 | Rush Hour |
| 2024-01-15 12:00 | 12 | 0 | 0 | Non-Rush Hour |
| 2024-01-15 18:00 | 18 | 0 | 1 | Rush Hour |
| 2024-01-20 08:00 | 8 | 1 | 0 | Non-Rush Hour (‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î) |

**‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢:**
```python
print(df['rush_hour_label'].value_counts())

# Output:
# 0 (Non-Rush)  75,840  (76%)
# 1 (Rush Hour) 24,160  (24%)
```

---

## 7Ô∏è‚É£ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

### **üíæ save_processed_data() - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å**

```python
def save_processed_data(self, df: pd.DataFrame, 
                        filepath: str = "outputs/processed_data.pkl"):
    """
    ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß
    
    Parameters:
        df: DataFrame ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ
        filepath: ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÑ‡∏ü‡∏•‡πå
    
    ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö:
        - .pkl: Pickle (‡πÄ‡∏£‡πá‡∏ß, ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏ö)
        - .csv: CSV (‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢, ‡πÅ‡∏ï‡πà‡∏ä‡πâ‡∏≤)
        - .parquet: Parquet (‡πÄ‡∏£‡πá‡∏ß, ‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î‡∏î‡∏µ)
    """
    
    import pickle
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metadata
    metadata = {
        'shape': df.shape,
        'columns': df.columns.tolist(),
        'dtypes': df.dtypes.to_dict(),
        'created_at': pd.Timestamp.now()
    }
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ metadata
    with open(filepath, 'wb') as f:
        pickle.dump({
            'data': df,
            'metadata': metadata
        }, f)
    
    print(f"‚úÖ Saved {df.shape[0]} samples to {filepath}")
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
processor.save_processed_data(
    processed_df,
    "outputs/processed_data_202401.pkl"
)

# Output:
# ‚úÖ Saved 125,430 samples to outputs/processed_data_202401.pkl
# File size: 45.3 MB
```

---

### **üìÇ load_processed_data() - ‡πÇ‡∏´‡∏•‡∏î**

```python
def load_processed_data(self, filepath: str) -> pd.DataFrame:
    """
    ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ß‡πâ
    
    Returns:
        DataFrame ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ
    """
    
    import pickle
    
    with open(filepath, 'rb') as f:
        data = pickle.load(f)
    
    df = data['data']
    metadata = data['metadata']
    
    print(f"‚úÖ Loaded {df.shape[0]} samples")
    print(f"   Created: {metadata['created_at']}")
    print(f"   Columns: {len(metadata['columns'])}")
    
    return df
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
# ‡πÇ‡∏´‡∏•‡∏î
df = processor.load_processed_data("outputs/processed_data_202401.pkl")

# Output:
# ‚úÖ Loaded 125,430 samples
#    Created: 2024-10-05 08:30:45
#    Columns: 18
```

---

## 8Ô∏è‚É£ Utility Functions - ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠

### **üìè haversine_distance() - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á**

```python
def haversine_distance(self, lat1: float, lon1: float,
                       lat2: float, lon2: float) -> float:
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏ö‡∏ô‡πÇ‡∏•‡∏Å (Great Circle Distance)
    
    Parameters:
        lat1, lon1: ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà 1
        lat2, lon2: ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà 2
    
    Returns:
        ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á (‡∏Å‡∏¥‡πÇ‡∏•‡πÄ‡∏°‡∏ï‡∏£)
    
    ‡∏™‡∏π‡∏ï‡∏£ Haversine:
        a = sin¬≤(Œîlat/2) + cos(lat1) √ó cos(lat2) √ó sin¬≤(Œîlon/2)
        c = 2 √ó arcsin(‚àöa)
        distance = R √ó c  (R = 6371 km)
    """
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô radians
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ú‡∏•‡∏ï‡πà‡∏≤‡∏á
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    
    # ‡∏™‡∏π‡∏ï‡∏£ Haversine
    a = np.sin(dlat/2)**2 + \
        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
    c = 2 * np.arcsin(np.sqrt(a))
    
    # ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á (km)
    R = 6371  # ‡∏£‡∏±‡∏®‡∏°‡∏µ‡πÇ‡∏•‡∏Å
    distance = R * c
    
    return distance
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
# Siam Square ‚Üí MBK Center
distance = processor.haversine_distance(
    13.7465, 100.5326,  # Siam
    13.7443, 100.5300   # MBK
)
print(f"Distance: {distance:.3f} km")
# Output: Distance: 0.323 km
```

---

### **‚úÖ validate_data() - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•**

```python
def validate_data(self, df: pd.DataFrame) -> Dict:
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    
    Returns:
        dict ‡∏ó‡∏µ‡πà‡∏°‡∏µ:
        - valid: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        - errors: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
        - warnings: ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô
        - statistics: ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    """
    
    errors = []
    warnings = []
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
    required_columns = [
        'timestamp', 'latitude', 'longitude', 
        'speed', 'road_id'
    ]
    missing = set(required_columns) - set(df.columns)
    if missing:
        errors.append(f"Missing columns: {missing}")
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á
    null_counts = df[required_columns].isnull().sum()
    if null_counts.any():
        warnings.append(f"Null values found: {null_counts[null_counts > 0].to_dict()}")
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡πà‡∏≤‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
    if (df['speed'] < 0).any():
        errors.append("Negative speed values found")
    
    if (df['speed'] > 150).any():
        warnings.append(f"Very high speeds: {df[df['speed'] > 150]['speed'].max()} km/h")
    
    # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
    statistics = {
        'total_samples': len(df),
        'date_range': (df['timestamp'].min(), df['timestamp'].max()),
        'unique_locations': df['road_id'].nunique(),
        'avg_speed': df['speed'].mean(),
        'speed_range': (df['speed'].min(), df['speed'].max())
    }
    
    return {
        'valid': len(errors) == 0,
        'errors': errors,
        'warnings': warnings,
        'statistics': statistics
    }
```

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:**
```python
validation = processor.validate_data(df)

if validation['valid']:
    print("‚úÖ Data is valid!")
else:
    print("‚ùå Errors found:")
    for error in validation['errors']:
        print(f"   - {error}")

print("\nüìä Statistics:")
for key, value in validation['statistics'].items():
    print(f"   {key}: {value}")
```

---

## üìä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

```python
# 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á processor
processor = TrafficDataProcessor(
    data_path="Data/PROBE-202401"
)

# 2. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
print("Loading probe data...")
probe_data = processor.load_probe_data("202401*")
print(f"Loaded {len(probe_data)} GPS points")

# 3. ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏ô‡∏ô
print("Loading road network...")
roads = processor.load_road_network(
    "Data/hotosm_tha_roads_lines_gpkg/roads.gpkg"
)

# 4. Map-matching
print("Map-matching...")
matched = processor.map_match_to_network(probe_data, max_distance=50)

# 5. Aggregate ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
print("Aggregating...")
aggregated = processor.aggregate_by_time(matched, bin_minutes=5)

# 6. ‡∏™‡∏£‡πâ‡∏≤‡∏á features
print("Creating features...")
features = processor.create_temporal_features(aggregated)
features = processor.create_statistical_features(features)
features = processor.create_lag_features(features, lags=[1, 2, 3])
features = processor.create_spatial_features(features)

# 7. ‡∏™‡∏£‡πâ‡∏≤‡∏á labels
print("Creating labels...")
final = processor.create_congestion_labels(features)
final = processor.create_rush_hour_labels(final)

# 8. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
print("Validating...")
validation = processor.validate_data(final)
print(f"Valid: {validation['valid']}")

# 9. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
print("Saving...")
processor.save_processed_data(
    final,
    "outputs/processed_data_202401.pkl"
)

print("‚úÖ Done!")
```

**Output:**
```
Loading probe data...
Loaded 2,450,320 GPS points

Loading road network...
Loaded 18,450 roads

Map-matching...
Matched 2,348,215 points (95.8%)

Aggregating...
Created 125,430 time bins

Creating features...
‚úì Temporal features (6)
‚úì Statistical features (7)
‚úì Lag features (9)
‚úì Spatial features (5)

Creating labels...
‚úì Congestion labels (4 classes)
‚úì Rush hour labels (2 classes)

Validating...
Valid: True

Saving...
‚úÖ Saved 125,430 samples to outputs/processed_data_202401.pkl

‚úÖ Done!
```

---

## üìà ‡∏™‡∏£‡∏∏‡∏õ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

| ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô | ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà | Input | Output |
|---------|---------|-------|--------|
| **load_probe_data()** | ‡πÇ‡∏´‡∏•‡∏î GPS | Files | DataFrame |
| **load_road_network()** | ‡πÇ‡∏´‡∏•‡∏î‡∏ñ‡∏ô‡∏ô | GeoPackage | GeoDataFrame |
| **map_match_to_network()** | ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏ñ‡∏ô‡∏ô | GPS points | Matched points |
| **aggregate_by_time()** | ‡∏£‡∏ß‡∏°‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤ | Raw data | 5-min bins |
| **create_temporal_features()** | Features ‡πÄ‡∏ß‡∏•‡∏≤ | DataFrame | +6 columns |
| **create_statistical_features()** | Features ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ | DataFrame | +7 columns |
| **create_lag_features()** | Features ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á | DataFrame | +9 columns |
| **create_spatial_features()** | Features ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà | DataFrame | +5 columns |
| **create_congestion_labels()** | Labels ‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏≤‡∏à‡∏£ | DataFrame | +2 columns |
| **create_rush_hour_labels()** | Labels ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô | DataFrame | +2 columns |
| **save_processed_data()** | ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å | DataFrame | .pkl file |
| **load_processed_data()** | ‡πÇ‡∏´‡∏•‡∏î | .pkl file | DataFrame |

---

## üéì ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏ó‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î

**DataFrame ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‡∏°‡∏µ 36 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå:**

### **Raw Data (6 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå):**
1. timestamp
2. latitude
3. longitude
4. speed
5. heading
6. quality

### **Map-Matched (2 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå):**
7. road_id
8. distance_to_road

### **Temporal Features (6 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå):**
9. hour_sin
10. hour_cos
11. day_of_week
12. is_weekend
13. is_holiday
14. time_since_rush_hour

### **Statistical Features (7 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå):**
15. speed_mean
16. speed_median
17. speed_std
18. speed_p25
19. speed_p75
20. speed_range
21. speed_cv

### **Lag Features (9 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå):**
22-24. speed_lag_1/2/3
25-27. speed_diff_1/2/3
28-30. congestion_lag_1/2/3

### **Spatial Features (5 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå):**
31. nearby_avg_speed
32. nearby_congestion
33. distance_to_center
34. road_density
35. is_main_road

### **Labels (4 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå):**
36. congestion_label (0-3)
37. congestion_name
38. rush_hour_label (0-1)
39. rush_hour_name

---

**‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠:** 5 ‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏° 2025  
**‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô:** 1.0  
**‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô:** Traffic GNN Classification Team
